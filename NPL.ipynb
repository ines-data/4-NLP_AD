{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "sms = pd.read_csv('SMSSpamCollection.txt', sep='\\t', names=[\"category\", \"message\"])\n",
    "print(len(sms))\n",
    "print(sms.info())\n",
    "sms.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type Data :  <class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "print(\"type Data : \",type(sms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        ham\n",
      "1        ham\n",
      "2       spam\n",
      "3        ham\n",
      "4        ham\n",
      "        ... \n",
      "5567    spam\n",
      "5568     ham\n",
      "5569     ham\n",
      "5570     ham\n",
      "5571     ham\n",
      "Name: category, Length: 5572, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(sms.category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1\n",
       "1       1\n",
       "2       0\n",
       "3       1\n",
       "4       1\n",
       "       ..\n",
       "5567    0\n",
       "5568    1\n",
       "5569    1\n",
       "5570    1\n",
       "5571    1\n",
       "Name: category, Length: 5572, dtype: object"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#change ham=1 , spam=0\n",
    "sms.category = sms.category.replace(['ham','spam'],['1','0'])\n",
    "\n",
    "sms.category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5572</td>\n",
       "      <td>5572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2</td>\n",
       "      <td>5169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>1</td>\n",
       "      <td>Sorry, I'll call later</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>4825</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       category                 message\n",
       "count      5572                    5572\n",
       "unique        2                    5169\n",
       "top           1  Sorry, I'll call later\n",
       "freq       4825                      30"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">message</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>747</td>\n",
       "      <td>653</td>\n",
       "      <td>Please call our customer service representativ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4825</td>\n",
       "      <td>4516</td>\n",
       "      <td>Sorry, I'll call later</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         message                                                            \\\n",
       "           count unique                                                top   \n",
       "category                                                                     \n",
       "0            747    653  Please call our customer service representativ...   \n",
       "1           4825   4516                             Sorry, I'll call later   \n",
       "\n",
       "               \n",
       "         freq  \n",
       "category       \n",
       "0           4  \n",
       "1          30  "
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = sms.groupby('category').describe()\n",
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>message</th>\n",
       "      <th>len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  category                                            message  len\n",
       "0        1  Go until jurong point, crazy.. Available only ...  111\n",
       "1        1                      Ok lar... Joking wif u oni...   29\n",
       "2        0  Free entry in 2 a wkly comp to win FA Cup fina...  155\n",
       "3        1  U dun say so early hor... U c already then say...   49\n",
       "4        1  Nah I don't think he goes to usf, he lives aro...   61"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms['len']= sms['message'].apply(len)\n",
    "sms.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "#stopwords\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DATE', 'SUNDAY']\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "# fonction clean word (stopwords) and no punctuation\n",
    "m = 'I HAVE A DATE ON SUNDAY WITH WILL!!'\n",
    "#m = 'Sample message! Notice: it has punctuation.'\n",
    "\n",
    "def punctuation_clean(m):\n",
    "    punct=[]\n",
    "    clean=[]\n",
    "    for item in m :\n",
    "        if item not in string.punctuation:\n",
    "            punct.append(item)\n",
    "            #print(punct1)\n",
    "            p=''.join(punct)\n",
    "            \n",
    "    for item in p.split():#punctuation(m).split():\n",
    "        if item.lower() not in stopwords.words('english'):\n",
    "            clean.append(item)\n",
    "    return clean\n",
    "print(punctuation_clean(m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Rofl', 'true', 'name']"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chek the fonction with another example\n",
    "#a = 'Had your mobile 11 months or more?'\n",
    "b = \"Rofl. Its true to its name\"\n",
    "punctuation_clean(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show if word in stopwords.words('english')\n",
    "'to' in stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Had', 'your', 'mobile', '11', 'months', 'or', 'more', '?']"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "#another method\n",
    "a = 'Had your mobile 11 months or more?'\n",
    "a = word_tokenize(a)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Had your mobile 11 months or more\n"
     ]
    }
   ],
   "source": [
    "# no punctuation\n",
    "def punctuation(a):\n",
    "    punct1=[]\n",
    "    for item in a :\n",
    "        if item not in string.punctuation:\n",
    "            punct1.append(item)\n",
    "            #print(punct1)\n",
    "            p=' '.join(punct1)\n",
    "    return p\n",
    "print(punctuation(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mobile', '11', 'months']\n"
     ]
    }
   ],
   "source": [
    "# clean word\n",
    "def clean_word(m):\n",
    "    clean=[]\n",
    "    for item in punctuation(m).split():\n",
    "        if item.lower() not in stopwords.words('english'):\n",
    "            clean.append(item)\n",
    "    return clean\n",
    "print(clean_word(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [Go, jurong, point, crazy, Available, bugis, n...\n",
       "1                       [Ok, lar, Joking, wif, u, oni]\n",
       "2    [Free, entry, 2, wkly, comp, win, FA, Cup, fin...\n",
       "3        [U, dun, say, early, hor, U, c, already, say]\n",
       "4    [Nah, dont, think, goes, usf, lives, around, t...\n",
       "5    [FreeMsg, Hey, darling, 3, weeks, word, back, ...\n",
       "6    [Even, brother, like, speak, treat, like, aids...\n",
       "7    [per, request, Melle, Melle, Oru, Minnaminungi...\n",
       "8    [WINNER, valued, network, customer, selected, ...\n",
       "9    [mobile, 11, months, U, R, entitled, Update, l...\n",
       "Name: message, dtype: object"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#chek the dataframe and fonction punctuation_clean\n",
    "sms['message'].head(10).apply(punctuation_clean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Go until jurong point, crazy.. Available only ...\n",
       "1                           Ok lar... Joking wif u oni...\n",
       "2       Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3       U dun say so early hor... U c already then say...\n",
       "4       Nah I don't think he goes to usf, he lives aro...\n",
       "                              ...                        \n",
       "5567    This is the 2nd time we have tried 2 contact u...\n",
       "5568                 Will ü b going to esplanade fr home?\n",
       "5569    Pity, * was in mood for that. So...any other s...\n",
       "5570    The guy did some bitching but I acted like i'd...\n",
       "5571                           Rofl. Its true to its name\n",
       "Name: message, Length: 5572, dtype: object"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Old dataframe\n",
    "sms['message']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorisation with fonction punctuation_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11425\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vect = CountVectorizer(analyzer=punctuation_clean)\n",
    "c = vect.fit(sms['message'].copy())\n",
    "\n",
    "# Print total number of vocab words\n",
    "print(len(c.vocabulary_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...\n"
     ]
    }
   ],
   "source": [
    "sms1 = sms['message'].copy()[0]\n",
    "print(sms1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 1110)\t1\n",
      "  (0, 1483)\t1\n",
      "  (0, 2060)\t1\n",
      "  (0, 4653)\t1\n",
      "  (0, 5217)\t1\n",
      "  (0, 5218)\t1\n",
      "  (0, 5769)\t1\n",
      "  (0, 6217)\t1\n",
      "  (0, 6906)\t1\n",
      "  (0, 6937)\t1\n",
      "  (0, 7555)\t1\n",
      "  (0, 7668)\t1\n",
      "  (0, 8336)\t1\n",
      "  (0, 8917)\t1\n",
      "  (0, 10965)\t1\n",
      "  (0, 11163)\t1\n",
      "(1, 11425)\n"
     ]
    }
   ],
   "source": [
    "SMS1 = transformer.transform([sms1])\n",
    "print(SMS1)\n",
    "print(SMS1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 1110)\t1\n",
      "  (0, 1483)\t1\n",
      "  (0, 2060)\t1\n",
      "  (0, 4653)\t1\n",
      "  (0, 5217)\t1\n",
      "  (0, 5218)\t1\n",
      "  (0, 5769)\t1\n",
      "  (0, 6217)\t1\n",
      "  (0, 6906)\t1\n",
      "  (0, 6937)\t1\n",
      "  (0, 7555)\t1\n",
      "  (0, 7668)\t1\n",
      "  (0, 8336)\t1\n",
      "  (0, 8917)\t1\n",
      "  (0, 10965)\t1\n",
      "  (0, 11163)\t1\n"
     ]
    }
   ],
   "source": [
    "#sms1 = messages['message'][0]\n",
    "print(SMS1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cine\n",
      "world\n"
     ]
    }
   ],
   "source": [
    "print(transformer.get_feature_names()[1483])\n",
    "print(transformer.get_feature_names()[11163])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorization without function punctuation_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rofl. Its true to its name\n",
      "(5572, 8577)\n",
      "type data : <class 'scipy.sparse.csr.csr_matrix'>\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "\n",
    "#stopwords\n",
    "#message = np.array(sms['message'])\n",
    "message = sms['message']\n",
    "#print(message)\n",
    "list_stopwords = nltk.corpus.stopwords.words('english')\n",
    "#stopwords = set(stopwords.words('english'))\n",
    "#stopwords=stopwords.words('english')\n",
    "CV = CountVectorizer(stop_words=list_stopwords)\n",
    "#CV = CountVectorizer()\n",
    "X = CV.fit_transform(message)\n",
    "print(message[5571])\n",
    "print(X.shape)\n",
    "print(\"type data :\", type(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5572, 8577)\n",
      "(5572,)\n"
     ]
    }
   ],
   "source": [
    "# it is necessary to make a verctorisation before\n",
    "X = X\n",
    "y = sms['category']\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model_LR = LogisticRegression()\n",
    "model_LR\n",
    "model_LR.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=model_LR.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1'], dtype=object)"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_LR.predict(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0']\n",
      "['0']\n",
      "['1']\n",
      "['1']\n"
     ]
    }
   ],
   "source": [
    "print(model_LR.predict(X[2]))\n",
    "print(model_LR.predict(X[5567]))\n",
    "print(model_LR.predict(X[5568]))\n",
    "print(model_LR.predict(X[5571]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision =  0.9979381443298969\n",
      "Recall =  0.9865771812080537\n",
      "Accuracy =  0.9964125560538116 fraction des échantillons correctement classés\n",
      "Accuracy =  1111 échantilloins correctement classés\n",
      "Score =  0.9964125560538116\n",
      "f1_score/spam =  0.9863945578231292\n",
      "f1_score/ham =  0.9979338842975207\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, accuracy_score\n",
    "\n",
    "\n",
    "print(\"Precision = \",precision_score(y_test, y_pred, average='macro'))\n",
    "#Score de classification de la précision      \n",
    "print(\"Recall = \", recall_score(y_test, y_pred, average='macro'))\n",
    "\n",
    "#renvoyez la fraction des échantillons correctement classés.\n",
    "print(\"Accuracy = \",accuracy_score(y_test, y_pred),\"fraction des échantillons correctement classés\")\n",
    "\n",
    "#renvoyez le nombre d'échantillons correctement classés\n",
    "print(\"Accuracy = \",accuracy_score(y_test, y_pred, normalize=False), \"échantilloins correctement classés\")\n",
    "\n",
    "#score\n",
    "print(\"Score = \",model_LR.score(x_test, y_test))\n",
    "\n",
    "#f1_score\n",
    "print(\"f1_score/spam = \", f1_score(y4_test, y4_pred, pos_label='0'))# spam = 0\n",
    "print(\"f1_score/ham = \", f1_score(y4_test, y4_pred, pos_label='1'))# ham = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5572, 8577)\n",
      "(5572,)\n"
     ]
    }
   ],
   "source": [
    "X1 = X\n",
    "y1 = sms['category']\n",
    "print(X1.shape)\n",
    "print(y1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x1_train, x1_test, y1_train, y1_test = train_test_split(X1, y1, test_size = 0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import svm\n",
    "\n",
    "#Create a svm Classifier\n",
    "model_SVM = svm.SVC(kernel='linear')\n",
    "#model_SVM = make_pipeline(SVC(gamma='auto'))\n",
    "model_SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_SVM.fit(X1, y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_pred=model_SVM.predict(x1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0']\n",
      "['0']\n",
      "['1']\n",
      "['1']\n"
     ]
    }
   ],
   "source": [
    "print(model_SVM.predict(X[2]))\n",
    "print(model_SVM.predict(X[5567]))\n",
    "print(model_SVM.predict(X[5568]))\n",
    "print(model_SVM.predict(X[5571]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision =  1.0\n",
      "Recall =  1.0\n",
      "Accuracy =  1.0 fraction des échantillons correctement classés\n",
      "Accuracy =  1115 échantilloins correctement classés\n",
      "Score =  0.9964125560538116\n",
      "f1_score/spam =  0.9863945578231292\n",
      "f1_score/ham =  0.9979338842975207\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "print(\"Precision = \",precision_score(y1_test, y1_pred, average='macro'))\n",
    "#Score de classification de la précision      \n",
    "print(\"Recall = \", recall_score(y1_test, y1_pred, average='macro'))\n",
    "\n",
    "#renvoyez la fraction des échantillons correctement classés.\n",
    "print(\"Accuracy = \",accuracy_score(y1_test, y1_pred),\"fraction des échantillons correctement classés\")\n",
    "\n",
    "#renvoyez le nombre d'échantillons correctement classés\n",
    "print(\"Accuracy = \",accuracy_score(y1_test, y1_pred, normalize=False), \"échantilloins correctement classés\")\n",
    "\n",
    "#score\n",
    "print(\"Score = \",model_LR.score(x1_test, y1_test))\n",
    "#score f1\n",
    "print(\"f1_score/spam = \", f1_score(y4_test, y4_pred, pos_label='0'))# spam = 0\n",
    "print(\"f1_score/ham = \", f1_score(y4_test, y4_pred, pos_label='1'))# ham = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# vectorization TfidfTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TfidfVectorizer Equivalent to \"CountVectorizer\" followed by \"TfidfTransformer\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5572,)\n",
      "5572\n",
      "(5572, 8577)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "corpus = sms.message\n",
    "print(corpus.shape)\n",
    "print(len(corpus))\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words=list_stopwords)\n",
    "X2 = vectorizer.fit_transform(corpus)\n",
    "#print(vectorizer.get_feature_names())\n",
    "print(X2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\"Sorry, I'll call later\", 30),\n",
       " ('I cant pick the phone right now. Pls send a message', 12),\n",
       " ('Ok...', 10),\n",
       " ('Please call our customer service representative on FREEPHONE 0808 145 4742 between 9am-11pm as you have WON a guaranteed £1000 cash or £5000 prize!',\n",
       "  4),\n",
       " ('Wen ur lovable bcums angry wid u, dnt take it seriously.. Coz being angry is d most childish n true way of showing deep affection, care n luv!.. kettoda manda... Have nice day da.',\n",
       "  4),\n",
       " ('Your opinion about me? 1. Over 2. Jada 3. Kusruthi 4. Lovable 5. Silent 6. Spl character 7. Not matured 8. Stylish 9. Simple Pls reply..',\n",
       "  4),\n",
       " ('7 wonders in My WORLD 7th You 6th Ur style 5th Ur smile 4th Ur Personality 3rd Ur Nature 2nd Ur SMS and 1st \"Ur Lovely Friendship\"... good morning dear',\n",
       "  4),\n",
       " ('Say this slowly.? GOD,I LOVE YOU &amp; I NEED YOU,CLEAN MY HEART WITH YOUR BLOOD.Send this to Ten special people &amp; u c miracle tomorrow, do it,pls,pls do it...',\n",
       "  4),\n",
       " ('Ok', 4),\n",
       " ('Ok.', 4)]"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.probability import FreqDist\n",
    "\n",
    "#frequence by sms\n",
    "f_describe = FreqDist(corpus)\n",
    "f_describe.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5572, 8577)\n",
      "(5572,)\n"
     ]
    }
   ],
   "source": [
    "X3 = X2\n",
    "y3 = sms['category']\n",
    "print(X3.shape)\n",
    "print(y3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x3_train, x3_test, y3_train, y3_test = train_test_split(X3, y3, test_size = 0.2, random_state=42)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model_LR2 = LogisticRegression()\n",
    "model_LR2\n",
    "model_LR2.fit(X3, y3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1'], dtype=object)"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y3_pred=model_LR2.predict(x3_test)\n",
    "model_LR2.predict(X3[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0']\n",
      "['0']\n",
      "['1']\n",
      "['1']\n"
     ]
    }
   ],
   "source": [
    "print(model_LR2.predict(X3[2]))\n",
    "print(model_LR2.predict(X3[5567]))\n",
    "print(model_LR2.predict(X3[5568]))\n",
    "print(model_LR2.predict(X3[5571]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision =  0.9883720930232558\n",
      "Recall =  0.9228187919463087\n",
      "Accuracy =  0.979372197309417 fraction des échantillons correctement classés\n",
      "Accuracy =  1092 échantilloins correctement classés\n",
      "Score =  0.8663677130044843\n",
      "f1_score/spam =  0.9863945578231292\n",
      "f1_score/ham =  0.9979338842975207\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "print(\"Precision = \",precision_score(y3_test, y3_pred, average='macro'))\n",
    "#Score de classification de la précision      \n",
    "print(\"Recall = \", recall_score(y3_test, y3_pred, average='macro'))\n",
    "\n",
    "#renvoyez la fraction des échantillons correctement classés.\n",
    "print(\"Accuracy = \",accuracy_score(y3_test, y3_pred),\"fraction des échantillons correctement classés\")\n",
    "\n",
    "#renvoyez le nombre d'échantillons correctement classés\n",
    "print(\"Accuracy = \",accuracy_score(y3_test, y3_pred, normalize=False), \"échantilloins correctement classés\")\n",
    "\n",
    "#score\n",
    "print(\"Score = \",model_LR.score(x3_test, y3_test))\n",
    "#score f1\n",
    "print(\"f1_score/spam = \", f1_score(y4_test, y4_pred, pos_label='0'))# spam = 0\n",
    "print(\"f1_score/ham = \", f1_score(y4_test, y4_pred, pos_label='1'))# ham = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5572, 8577)\n",
      "(5572,)\n"
     ]
    }
   ],
   "source": [
    "X4 = X2\n",
    "y4 = sms['category']\n",
    "print(X4.shape)\n",
    "print(y4.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x4_train, x4_test, y4_train, y4_test = train_test_split(X4, y4, test_size = 0.2, random_state=42)\n",
    "\n",
    "#Create a svm Classifier\n",
    "model_SVM2 = svm.SVC(kernel='linear')\n",
    "#model_SVM = make_pipeline(SVC(gamma='auto'))\n",
    "model_SVM2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_SVM2.fit(X4, y4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "y4_pred=model_SVM2.predict(x4_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0']\n",
      "['0']\n",
      "['1']\n",
      "['1']\n"
     ]
    }
   ],
   "source": [
    "print(model_SVM2.predict(X4[2]))\n",
    "print(model_SVM2.predict(X4[5567]))\n",
    "print(model_SVM2.predict(X4[5568]))\n",
    "print(model_SVM2.predict(X4[5571]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision =  0.9979381443298969\n",
      "Recall =  0.9865771812080537\n",
      "Accuracy =  0.9964125560538116 fraction des échantillons correctement classés\n",
      "Accuracy =  1111 échantilloins correctement classés\n",
      "Score =  0.8663677130044843\n",
      "f1_score/spam =  0.9863945578231292\n",
      "f1_score/ham =  0.9979338842975207\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "print(\"Precision = \",precision_score(y4_test, y4_pred, average='macro'))\n",
    "#Score de classification de la précision      \n",
    "print(\"Recall = \", recall_score(y4_test, y4_pred, average='macro'))\n",
    "\n",
    "#renvoyez la fraction des échantillons correctement classés.\n",
    "print(\"Accuracy = \",accuracy_score(y4_test, y4_pred),\"fraction des échantillons correctement classés\")\n",
    "\n",
    "#renvoyez le nombre d'échantillons correctement classés\n",
    "print(\"Accuracy = \",accuracy_score(y4_test, y4_pred, normalize=False), \"échantilloins correctement classés\")\n",
    "\n",
    "#score\n",
    "print(\"Score = \",model_LR.score(x4_test, y4_test))\n",
    "#score f1\n",
    "print(\"f1_score/spam = \", f1_score(y4_test, y4_pred, pos_label='0'))# spam = 0\n",
    "print(\"f1_score/ham = \", f1_score(y4_test, y4_pred, pos_label='1'))# ham = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5572, 8577)\n",
      "(5572,)\n"
     ]
    }
   ],
   "source": [
    "X5 = X2\n",
    "y5 = sms['category']\n",
    "print(X5.shape)\n",
    "print(y5.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99103943, 0.97670251, 0.98384201, 0.98743268, 0.97486535,\n",
       "       0.98204668, 0.97845601, 0.97845601, 0.98384201, 0.97666068])"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "#Create a svm Classifier\n",
    "model_SVM3 = svm.SVC(kernel='linear')\n",
    "model_SVM3\n",
    "scores = cross_val_score(model_SVM3, X5, y5, cv=10)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(type(list(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean =  0.981334337174958\n"
     ]
    }
   ],
   "source": [
    "import statistics\n",
    "import numpy as np\n",
    "\n",
    "print(\"Mean = \", scores.mean())\n",
    "#print(\"Standard Deviation = \", np.array([scores]).stdev())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.009923244018959308"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.std()*2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross validation ShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "\n",
    "X6 = X2\n",
    "y6 = sms.category\n",
    "\n",
    "\n",
    "rs = ShuffleSplit(n_splits=10, test_size=.2, random_state=42)\n",
    "\n",
    "rs.get_n_splits(X6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ShuffleSplit(n_splits=10, random_state=42, test_size=0.2, train_size=None)\n"
     ]
    }
   ],
   "source": [
    "print(rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_scores/spam =  [0.9863945578231292, 0.9869281045751634, 0.9908814589665653, 0.9928571428571429, 0.9860139860139859, 0.9802631578947368, 0.989399293286219, 0.9768976897689768, 0.9817073170731707, 0.9811320754716981]\n",
      "f1_scores/ham =  [0.9979338842975207, 0.9979209979209979, 0.9984218832193582, 0.9989743589743589, 0.9979423868312757, 0.9968847352024922, 0.9984591679506933, 0.9963674104826155, 0.9968454258675079, 0.9968619246861925]\n",
      "mean score/spam =  0.9852474783730789\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "#Create a svm Classifier\n",
    "model_SVM4 = svm.SVC(kernel='linear')\n",
    "\n",
    "\n",
    "\n",
    "ShuffleSplit(n_splits=10, random_state=0, test_size=0.2, train_size=None)\n",
    "\n",
    "f1_scores_spam = []\n",
    "f1_scores_ham = []\n",
    "\n",
    "for train_index, test_index in rs.split(X6):\n",
    "    x6_train, x6_test = X6[train_index], X6[test_index]\n",
    "    y6_train, y6_test = y6[train_index], y6[test_index]\n",
    "    \n",
    "    model_SVM4.fit(X6,y6)\n",
    "    \n",
    "    y6_pred=model_SVM4.predict(x6_test)\n",
    "    f1_score_spam = f1_score(y6_test, y6_pred, pos_label='0')\n",
    "    f1_scores_spam.append(f1_score_spam)\n",
    "    f1_score_ham = f1_score(y6_test, y6_pred, pos_label='1')\n",
    "    f1_scores_ham.append(f1_score_ham)\n",
    "    \n",
    "print(\"f1_scores/spam = \", f1_scores_spam )\n",
    "\n",
    "print(\"f1_scores/ham = \", f1_scores_ham )\n",
    "\n",
    "#print(\"mean score/spam = \", np.array([f1_scores_spam.mean()]))\n",
    "print(\"mean score/spam = \", np.array([f1_scores_spam]).mean())\n",
    "\n",
    "\n",
    " #   print(\"Train:\", train_index, \"TEST:\", test_index, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean score/spam =  0.9852474783730789\n",
      "mean score/ham =  0.9976612175433015\n"
     ]
    }
   ],
   "source": [
    "print(\"mean score/spam = \", np.array([f1_scores_spam]).mean())\n",
    "print(\"mean score/ham = \", np.array([f1_scores_ham]).mean())\n",
    "#print(\"ecart type score/spam = \", np.array([f1_scores_spam].sdt()*2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean f1 score/spam</th>\n",
       "      <th>mean f1 score/ham</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cross validation</th>\n",
       "      <td>0.985247</td>\n",
       "      <td>0.997661</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  mean f1 score/spam  mean f1 score/ham\n",
       "cross validation            0.985247           0.997661"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df = pd.DataFrame({'mean f1 score/spam':0.9852474783730789, 'mean f1 score/ham':0.9976612175433015}\n",
    "                  , index=['cross validation'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
